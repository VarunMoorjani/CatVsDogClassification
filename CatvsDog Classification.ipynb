{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PnuEhQmBirFO"
   },
   "source": [
    "# Dog vs Cat classification\n",
    "\n",
    "\n",
    "- Image classification using convolutional neural networks.\n",
    "- Regularization: Data augmentation\n",
    "- Regularization: Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 525,
     "status": "ok",
     "timestamp": 1569595722426,
     "user": {
      "displayName": "Nazanin Makkinejad",
      "photoUrl": "",
      "userId": "01874513099563019434"
     },
     "user_tz": 300
    },
    "id": "CThsHu8hjOIY",
    "outputId": "c1837242-38f9-47fb-e5eb-a375fed577c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bndZE2TcirFQ"
   },
   "source": [
    "## Download the data\n",
    "www.kaggle.com/c/dogs-vs-cats/data\n",
    "\n",
    "The dataset contains 25,000 images of cats, and 25,000 images of dogs, but in this example we'll only use a subset of the data. A training set with 1,000 samples of each class, a validation set with 500 samples of each class, and a test set with 500 samples of each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4EPm914yK-YT"
   },
   "source": [
    "The wget command is a command line utility for downloading files from the Internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7139,
     "status": "ok",
     "timestamp": 1569597606258,
     "user": {
      "displayName": "Nazanin Makkinejad",
      "photoUrl": "",
      "userId": "01874513099563019434"
     },
     "user_tz": 300
    },
    "id": "2Q_5FEJeGgLi",
    "outputId": "0e083c38-c8dd-4615-9765-2830be12abcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: wget: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!wget -c https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KpWVxv77J__2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open kagglecatsanddogs_3367a.zip, kagglecatsanddogs_3367a.zip.zip or kagglecatsanddogs_3367a.zip.ZIP.\r\n"
     ]
    }
   ],
   "source": [
    "!unzip -qq kagglecatsanddogs_3367a.zip -d Cat_Dog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GfjQlKU-irFR"
   },
   "source": [
    "## 1-Preparing data into different directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LempzRptirFR"
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "\n",
    "original_dataset_dir = '/content/Cat_Dog/PetImages'\n",
    "/Users/shubpuri/Downloads/\n",
    "!rm -r data_processed\n",
    "base_dir = '/content/data_processed'\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "os.mkdir(train_cats_dir)\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "os.mkdir(train_dogs_dir)\n",
    "\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "os.mkdir(validation_cats_dir)\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "os.mkdir(validation_dogs_dir)\n",
    "\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "os.mkdir(test_cats_dir)\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "os.mkdir(test_dogs_dir)\n",
    "\n",
    "fnames = ['{}.jpg'.format(i) for i in range(1001) if i!=666]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, 'Cat', fname)\n",
    "    dst = os.path.join(train_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "fnames = ['{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, 'Cat', fname)\n",
    "    dst = os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "fnames = ['{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, 'Cat', fname)\n",
    "    dst = os.path.join(test_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "fnames = ['{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, 'Dog', fname)\n",
    "    dst = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "fnames = ['{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, 'Dog', fname)\n",
    "    dst = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "fnames = ['{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, 'Dog', fname)\n",
    "    dst = os.path.join(test_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bXwEZ2xxirFU"
   },
   "source": [
    "This is a balanced binary-classification problem, which means classification accuracy will be an appropriate measure of success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 443,
     "status": "ok",
     "timestamp": 1569598724082,
     "user": {
      "displayName": "Nazanin Makkinejad",
      "photoUrl": "",
      "userId": "01874513099563019434"
     },
     "user_tz": 300
    },
    "id": "RI_eIZZSirFV",
    "outputId": "4748f1aa-b1ba-4672-fb7b-0b137854d033"
   },
   "outputs": [],
   "source": [
    "print('total training cat images:', len(os.listdir(train_cats_dir))) \n",
    "print('total training dog images:', len(os.listdir(train_dogs_dir)))\n",
    "print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
    "print('total validation dog images:', len(os.listdir(validation_dogs_dir)))\n",
    "print('total test cat images:', len(os.listdir(test_cats_dir)))\n",
    "print('total test dog images:', len(os.listdir(test_dogs_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DkJz7QWxirFY"
   },
   "source": [
    "## 2- Build your network\n",
    "The convnet will be a stack of alternated Conv2D (with relu activation) and MaxPooling2D layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zKhdfdtAirFZ"
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 450,
     "status": "ok",
     "timestamp": 1569598727861,
     "user": {
      "displayName": "Nazanin Makkinejad",
      "photoUrl": "",
      "userId": "01874513099563019434"
     },
     "user_tz": 300
    },
    "id": "QbPlt174irFb",
    "outputId": "b3f94816-3ad4-4210-9386-1e2e4f51f38c"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6hPRtEdDirFe"
   },
   "source": [
    "## 3- Configure the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BLL0lH4MirFe"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8wcky7b2irFg"
   },
   "source": [
    "## 4- Data preprocessing\n",
    "\n",
    "Data should be formatted into appropriately preprocessed floating- point tensors before being fed into the network. Currently, the data sits on a drive as JPEG files, so the steps for getting it into the network are roughly as follows:\n",
    "\n",
    "1. Read the picture files.\n",
    "\n",
    "2. Decode the JPEG content to RGB grids of pixels.\n",
    "\n",
    "3. Convert these into floating-point tensors.\n",
    "\n",
    "4. Rescale the pixel values (between 0 and 255) to the [0, 1] interval.\n",
    "\n",
    "It may seem a bit daunting, but fortunately Keras has utilities to take care of these steps automatically. Keras has a module with image-processing helper tools, located at keras.preprocessing.image. In particular, it contains the class __ImageDataGenerator__, which lets you quickly set up Python generators that can automatically turn image files on disk into batches of preprocessed tensors. This is what you’ll use here.\n",
    "\n",
    "For __ImageDataGenerator__ see this website: https://keras.io/preprocessing/image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 470,
     "status": "ok",
     "timestamp": 1569598730763,
     "user": {
      "displayName": "Nazanin Makkinejad",
      "photoUrl": "",
      "userId": "01874513099563019434"
     },
     "user_tz": 300
    },
    "id": "ZlHsHJwHirFh",
    "outputId": "8933e47c-58ae-4dee-e45a-113cc9493d81"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_7d5A3h6irFk"
   },
   "source": [
    "A Python generator is an object that acts as an iterator: it’s an object you can use with the for ... in operator. Generators are built using the yield operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 439,
     "status": "ok",
     "timestamp": 1569598733134,
     "user": {
      "displayName": "Nazanin Makkinejad",
      "photoUrl": "",
      "userId": "01874513099563019434"
     },
     "user_tz": 300
    },
    "id": "36TQMRIRirFl",
    "outputId": "002aa3b5-828e-4c58-8b67-4d47481e6bf9"
   },
   "outputs": [],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5tamaOxsirFo"
   },
   "source": [
    "## 5- Fit model\n",
    "Let’s fit the model to the data using the generator. You do so using the fit_generator method, the equivalent of fit for data generators like this one. It expects as its first argument a Python generator that will yield batches of inputs and targets indefinitely, like this one does. Because the data is being generated endlessly, the Keras model needs to know how many samples to draw from the generator before declaring an epoch over. This is the role of the steps_per_epoch argument: after having drawn steps_per_epoch batches from the generator—that is, after having run for steps_per_epoch gradient descent steps—the fitting process will go to the next epoch. In this case, batches are 20 samples, so it will take 100 batches until you see your target of 2,000 samples.\n",
    "\n",
    "When using fit_generator, you can pass a validation_data argument, much as with the fit method. It’s important to note that this argument is allowed to be a data generator, but it could also be a tuple of Numpy arrays. If you pass a generator as validation_data, then this generator is expected to yield batches of validation data endlessly; thus you should also specify the validation_steps argument, which tells the process how many batches to draw from the validation generator for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fXy0G6A1irFp",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q-UvLuR3irFs"
   },
   "source": [
    "## 6- Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1lR5ENHnirFs"
   },
   "outputs": [],
   "source": [
    "model.save('cats_and_dogs_small_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U3YnEezSirFv"
   },
   "source": [
    "## 7- Plot loss/accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 975,
     "status": "ok",
     "timestamp": 1569599065224,
     "user": {
      "displayName": "Nazanin Makkinejad",
      "photoUrl": "",
      "userId": "01874513099563019434"
     },
     "user_tz": 300
    },
    "id": "dQdQiFIzirFw",
    "outputId": "13ce8f7d-5f2a-4f22-f8c7-38ea6f11419a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NeKT26OAirF1"
   },
   "source": [
    "These plots are characteristic of overfitting. The training accuracy increases linearly over time, until it reaches nearly 100%, whereas the validation accuracy stalls at 70–72%. The validation loss reaches its minimum after only five epochs and then stalls, whereas the training loss keeps decreasing linearly until it reaches nearly 0.\n",
    "\n",
    "Because you have relatively few training samples (2,000), overfitting will be your number-one concern. You already know about a number of techniques that can help mitigate overfitting, such as dropout and weight decay (L2 regularization). We’re now going to work with a new one, specific to computer vision and used almost universally when processing images with deep-learning models: data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vIOTCCuHirF2"
   },
   "source": [
    "## 8- Use data augmentation to mitigate overfitting\n",
    "Data augmentation takes the approach of generating more training data from existing training samples, by augmenting the samples via a number of random transformations that yield believable-looking images. The goal is that at training time, your model will never see the exact same picture twice. This helps expose the model to more aspects of the data and generalize better.\n",
    "\n",
    "In Keras, this can be done by configuring a number of random transformations to be performed on the images read by the ImageDataGenerator instance. Let’s get started with an example. (for more, see the Keras documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fn2E3892irF2"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TBBEMVXcirF4"
   },
   "source": [
    "Display some randomly augmented training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2157,
     "status": "ok",
     "timestamp": 1569600464458,
     "user": {
      "displayName": "Nazanin Makkinejad",
      "photoUrl": "",
      "userId": "01874513099563019434"
     },
     "user_tz": 300
    },
    "id": "tZPkT9z0irF5",
    "outputId": "d82e2a9a-9b90-4a7a-de25-58dc52520dee"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "fnames = [os.path.join(train_cats_dir, fname) for fname in os.listdir(train_cats_dir)]\n",
    "  \n",
    "# Choose an image to augment\n",
    "img_path = fnames[4]\n",
    "\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "\n",
    "# Converts it to a Numpy array with shape (150, 150, 3) \n",
    "x = image.img_to_array(img) \n",
    "\n",
    "# Reshapes it to (1, 150, 150, 3)\n",
    "x = x.reshape((1,) + x.shape) \n",
    "\n",
    "i=0\n",
    "for batch in datagen.flow(x, batch_size=1):\n",
    "    plt.figure(i)\n",
    "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
    "    i += 1\n",
    "    if i % 4 == 0:\n",
    "        break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HXdrJL__irF9"
   },
   "source": [
    "To further fight overfitting, you’ll also add a __Dropout__ layer to your model, right before the densely connected classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 454,
     "status": "ok",
     "timestamp": 1569600495054,
     "user": {
      "displayName": "Nazanin Makkinejad",
      "photoUrl": "",
      "userId": "01874513099563019434"
     },
     "user_tz": 300
    },
    "id": "fybbQRbgirF-",
    "outputId": "299fa18a-7c93-4f1e-f5f4-b5b45f8bc39f"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7JZ5Ue70irGA"
   },
   "source": [
    "Let’s train the network using data augmentation and dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 114026,
     "status": "error",
     "timestamp": 1569600654451,
     "user": {
      "displayName": "Nazanin Makkinejad",
      "photoUrl": "",
      "userId": "01874513099563019434"
     },
     "user_tz": 300
    },
    "id": "BEW50TdEirGB",
    "outputId": "aa919183-b960-44f5-d96e-220e8442063f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n",
    "    \n",
    "    \n",
    "# Note that the validation data shouldn't be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=100,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h41LgdaPirGG"
   },
   "outputs": [],
   "source": [
    "model.save('cats_and_dogs_small_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 550,
     "status": "ok",
     "timestamp": 1564167567082,
     "user": {
      "displayName": "Nazanin Makkinejad",
      "photoUrl": "",
      "userId": "01874513099563019434"
     },
     "user_tz": 300
    },
    "id": "oLvrYhjXirGK",
    "outputId": "cfcb8ec4-7eed-4fae-e3f6-73f57ad21821"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y8XkGhryirGN"
   },
   "source": [
    "Thanks to data augmentation and dropout, there is no longer overfitting: the training curves are closely tracking the validation curves. \n",
    "\n",
    "Now an accuracy of 82%, a 15% relative improvement over the non-regularized model can be achieved."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lecture6_python.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
